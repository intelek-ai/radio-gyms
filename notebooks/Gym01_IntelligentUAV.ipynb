{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfd370e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/supawat/Code/radio-gyms\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "897a2445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-macosx_10_14_x86_64.whl (217.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 217.4 MB 1.1 MB/s eta 0:00:01    |████▊                           | 32.2 MB 1.6 MB/s eta 0:01:54     |████████████████████████████▊   | 194.9 MB 1.4 MB/s eta 0:00:16\n",
      "\u001b[?25hCollecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-macosx_10_9_x86_64.whl (13.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.0 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp38-cp38-macosx_10_10_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from tensorflow) (1.22.3)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.0-cp38-cp38-macosx_10_9_x86_64.whl (35 kB)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from tensorflow) (58.0.4)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from tensorflow) (4.1.1)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.20.0-cp38-cp38-macosx_10_9_x86_64.whl (962 kB)\n",
      "\u001b[K     |████████████████████████████████| 962 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 859 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.1.1-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.3-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/envs/radio-gyms/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=3bab753493f0b198de898c0f2d5e651999c2921cb4aa79632e813c03294179ff\n",
      "  Stored in directory: /Users/supawat/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 h5py-3.6.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.20.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109 werkzeug-2.1.1 wrapt-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25cbf3e",
   "metadata": {},
   "source": [
    "## Import Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b581aaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b12464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radio_gyms.gyms import LocationGym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a415c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_SCENE = \"./assets/models/poznan.obj\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38870f50",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26649665",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = tf.keras.layers.Dense(state_N,activation='relu')\n",
    "        self.l2 = tf.keras.layers.Dense(state_N/2,activation='relu')\n",
    "        self.v = tf.keras.layers.Dense(1, activation = None)\n",
    "        \n",
    "    def call(self, input_):\n",
    "        output_ = self.l1(input_)\n",
    "        output_ = self.l2(output_)\n",
    "        output_ = self.v(output_)\n",
    "        return output_\n",
    "    \n",
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = tf.keras.layers.Dense(state_N,activation='relu')\n",
    "        self.l2 = tf.keras.layers.Dense(state_N/2,activation='relu')\n",
    "        self.v = tf.keras.layers.Dense(action_N, activation = 'softmax')\n",
    "        \n",
    "    def call(self, input_):\n",
    "        output_ = self.l1(input_)\n",
    "        output_ = self.l2(output_)\n",
    "        output_ = self.v(output_)\n",
    "        return output_\n",
    "    \n",
    "class Agent():\n",
    "    def __init__(self, gamma=0.99):\n",
    "        self.gamma = gamma\n",
    "        self.a_opt = tf.keras.optimizers.Adam(learning_rate=5e-6)\n",
    "        self.c_opt = tf.keras.optimizers.Adam(learning_rate=5e-6)\n",
    "        try:\n",
    "            self.actor = tf.keras.models.load_model(actor_path, compile=False)\n",
    "            self.critic = tf.keras.models.load_model(critic_path, compile=False)\n",
    "            print(\"Loaded the saved model\")\n",
    "        except:\n",
    "            print(\"Created the new model\")\n",
    "            self.actor = Actor()\n",
    "            self.critic = Critic()\n",
    "        \n",
    "    def act(self, state):\n",
    "        prob = self.actor(np.array([state]))\n",
    "        print(prob)\n",
    "        prob = prob.numpy()\n",
    "        dist = tfp.distributions.Categorical(probs=prob, dtype=tf.float32)\n",
    "        action = dist.sample()\n",
    "        return int(action.numpy()[0])\n",
    "    \n",
    "    def actor_loss(self, prob, action, td):\n",
    "        dist = tfp.distributions.Categorical(probs=prob, dtype=tf.float32)\n",
    "        log_prob = dist.log_prob(action)\n",
    "        loss = -log_prob*td\n",
    "        return loss\n",
    "    \n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        state = np.array([state])\n",
    "        next_state = np.array([next_state])\n",
    "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "            p = self.actor(state, training=True)\n",
    "            v =  self.critic(state,training=True)\n",
    "            vn = self.critic(next_state, training=True)\n",
    "            td = reward + self.gamma*vn*(1-int(done)) - v\n",
    "            a_loss = self.actor_loss(p, action, td)\n",
    "            c_loss = td**2\n",
    "        grads1 = tape1.gradient(a_loss, self.actor.trainable_variables)\n",
    "        grads2 = tape2.gradient(c_loss, self.critic.trainable_variables)\n",
    "        self.a_opt.apply_gradients(zip(grads1, self.actor.trainable_variables))\n",
    "        self.c_opt.apply_gradients(zip(grads2, self.critic.trainable_variables))\n",
    "        return a_loss, c_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b18c87",
   "metadata": {},
   "source": [
    "## Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9365ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d01a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym = LocationGym(MAP_SCENE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_n = 10\n",
    "for ep in range(episode_n):\n",
    "    done = False\n",
    "    state = gym.get_states()\n",
    "    total_reward = 0\n",
    "    rewards = []\n",
    "    while not done:\n",
    "        actions = agent.act(state)\n",
    "        gym.action(actions)\n",
    "        gym.step()\n",
    "        reward = gym.get_reward()\n",
    "        next_states = gym.get_states()\n",
    "        rewards.append(rewards)\n",
    "        a_loss, c_loss = agent.learn(states, actions, reward, next_states)\n",
    "        states = next_states    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e427e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57132e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
